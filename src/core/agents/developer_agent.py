from typing import Any, Optional, List, Tuple # Added Tuple
import structlog
import re

from src.core.base_agent import AbstractBaseAgent, LLMAggregator, ToolsRegistry
from src.core.agent_structures import AgentConfig, TaskContext, TaskResult
from src.core.planning_structures import TaskStatus, Task
from src.models import ChatMessage
from src.core.tool_interface import ToolOutput # For type hinting tool outputs

logger = structlog.get_logger(__name__)

def _parse_path_from_description(text: str, keyword: str) -> Optional[str]:
    match = re.search(rf"{keyword}\s*'([^']*)'", text, re.IGNORECASE)
    if match:
        return match.group(1)
    return None


class DeveloperAgent(AbstractBaseAgent):
    def __init__(
        self,
        agent_config: AgentConfig,
        llm_aggregator: LLMAggregator,
        tools_registry: Optional[ToolsRegistry] = None,
    ):
        super().__init__(agent_config, llm_aggregator, tools_registry)
        logger.info(f"DeveloperAgent ({self.agent_config.agent_id}) initialized.")

    async def _sop_analyze_requirements(self, task_description: str, context: TaskContext) -> str:
        logger.debug(f"Agent {self.agent_config.agent_id}: SOP Step - Analyzing Requirements for task: {task_description[:100]}...")
        # For now, this is a simple pass-through or slight refinement.
        # Could involve an LLM call to clarify or break down complex requirements.
        # Example:
        # messages = [
        #     ChatMessage(role="system", content="You are a requirements analysis expert."),
        #     ChatMessage(role="user", content=f"Clarify and itemize the core software development requirements from this task: {task_description}")
        # ]
        # response = await self._use_llm(messages)
        # refined_requirements = response.choices[0].message.content or task_description
        refined_requirements = f"Refined requirements for: {task_description}" # Placeholder
        logger.debug(f"Agent {self.agent_config.agent_id}: SOP Step - Requirements Analysis Complete.")
        return refined_requirements

    async def _sop_read_initial_files(self, task_description: str, context: TaskContext) -> Tuple[str, Optional[str]]:
        logger.debug(f"Agent {self.agent_config.agent_id}: SOP Step - Reading Initial Files...")
        combined_content = ""
        error_str: Optional[str] = None

        # Simple check if "read file" is in the original task description
        if "read file" in task_description.lower():
            parsed_path = _parse_path_from_description(task_description, "read file")
            if parsed_path:
                logger.info(f"Reading file: {parsed_path} as part of SOP.")
                read_tool_output: ToolOutput = await self._use_tool("file_read", {"file_path": parsed_path})
                if read_tool_output.error:
                    error_str = f"Error reading file {parsed_path}: {read_tool_output.error} (Code: {read_tool_output.status_code})"
                    logger.warn(error_str)
                else:
                    combined_content = str(read_tool_output.output)
                    logger.info(f"Successfully read file {parsed_path}.")
            else:
                logger.info("'read file' mentioned but path not parsable in standard format.")

        logger.debug(f"Agent {self.agent_config.agent_id}: SOP Step - Initial File Reading Complete.")
        return combined_content, error_str

    async def _sop_generate_code(self, requirements: str, existing_code: Optional[str], context: TaskContext) -> Tuple[str, Optional[str]]:
        logger.debug(f"Agent {self.agent_config.agent_id}: SOP Step - Generating Code...")
        error_str: Optional[str] = None

        prompt_content = requirements
        if existing_code:
            prompt_content = f"Original requirements:\n{requirements}\n\nExisting code/context from files:\n{existing_code}\n\nPlease generate or modify code based on this."
        else:
            prompt_content = f"Please generate code based on these requirements:\n{requirements}"

        try:
            messages = [
                ChatMessage(role="system", content="You are a senior software developer. Generate concise, efficient, and correct code based on the requirements. If modifying existing code, clearly indicate changes or provide the complete updated code block."),
                ChatMessage(role="user", content=prompt_content)
            ]
            response = await self._use_llm(messages)
            generated_code = response.choices[0].message.content if response.choices and response.choices[0].message else "No code generated by LLM."
            logger.info("Code generation via LLM successful.")
        except Exception as e:
            logger.error(f"LLM call for code generation failed: {e}", exc_info=True)
            generated_code = f"Error: LLM code generation failed: {str(e)}"
            error_str = "LLM code generation failed."

        logger.debug(f"Agent {self.agent_config.agent_id}: SOP Step - Code Generation Complete.")
        return generated_code, error_str

    async def _sop_self_critique(self, generated_code: str, requirements: str, context: TaskContext) -> Tuple[str, Optional[str]]:
        logger.debug(f"Agent {self.agent_config.agent_id}: SOP Step - Performing Self-Critique...")
        error_str: Optional[str] = None
        # Placeholder: In a real scenario, this would involve specific LLM prompts
        # to review the code for correctness, adherence to requirements, bugs, etc.
        # For now, we'll just log and return the code as is, or simulate a minor refinement.

        # Example of a refinement (could be an LLM call):
        # if "some_specific_pattern_to_fix" in generated_code:
        #    refined_code = generated_code.replace("some_specific_pattern_to_fix", "corrected_pattern")
        #    logger.info("Self-critique identified and applied a refinement.")
        #    return refined_code, None

        logger.info("Self-critique step (placeholder) completed. No changes made to the code.")
        refined_code = generated_code # No actual critique/refinement in this placeholder
        logger.debug(f"Agent {self.agent_config.agent_id}: SOP Step - Self-Critique Complete.")
        return refined_code, error_str

    async def _sop_write_output_files(self, code_to_write: str, task_description: str, context: TaskContext) -> Optional[str]:
        logger.debug(f"Agent {self.agent_config.agent_id}: SOP Step - Writing Output Files...")
        error_str: Optional[str] = None

        if "write file" in task_description.lower():
            parsed_path = _parse_path_from_description(task_description, "write file")
            if parsed_path:
                logger.info(f"Writing output code/text to file: {parsed_path}")
                write_tool_output: ToolOutput = await self._use_tool("file_write", {"file_path": parsed_path, "content": code_to_write})
                if write_tool_output.error:
                    error_str = f"Error writing output file {parsed_path}: {write_tool_output.error} (Code: {write_tool_output.status_code})"
                    logger.warn(error_str)
                else:
                    logger.info(f"Successfully wrote output to {parsed_path}.")
            else:
                logger.info("'write file' mentioned but path not parsable for output writing.")
                # This might not be an error for the SOP itself, but a note.
                # error_str = "Output file path not specified clearly though 'write file' was mentioned."

        logger.debug(f"Agent {self.agent_config.agent_id}: SOP Step - Output File Writing Complete.")
        return error_str

    async def execute_task(self, task: Task, context: TaskContext) -> TaskResult:
        current_task_obj = context.current_task
        task_id_to_report = current_task_obj.task_id
        original_task_description = current_task_obj.description

        logger.info(f"DeveloperAgent ({self.agent_config.agent_id}) starting SOP for task: {task_id_to_report} - {original_task_description}")
        final_output_parts: List[str] = [f"Task: {original_task_description}"]
        overall_status: TaskStatus = TaskStatus.COMPLETED

        if not original_task_description:
            logger.error(f"Task {task_id_to_report} has no description.")
            return TaskResult(task_id=task_id_to_report, status=TaskStatus.FAILED, error_message="Task has no description.")

        # SOP Step 1: Analyze Requirements
        requirements = await self._sop_analyze_requirements(original_task_description, context)
        final_output_parts.append(f"Analyzed Requirements: {requirements}")

        # SOP Step 2: Read Initial Files (if any mentioned)
        existing_code_content, err_read = await self._sop_read_initial_files(original_task_description, context)
        if err_read:
            final_output_parts.append(f"File Reading Note: {err_read}")
            # Depending on policy, this might not set overall_status to FAILED if reading is optional
        if existing_code_content:
            final_output_parts.append(f"Initial File Content (summary): {existing_code_content[:200]}...")


        # SOP Step 3: Generate Code
        generated_code, err_gen = await self._sop_generate_code(requirements, existing_code_content, context)
        if err_gen:
            final_output_parts.append(f"Code Generation Error: {err_gen}")
            overall_status = TaskStatus.FAILED
        final_output_parts.append(f"Generated Code/Text:\n{generated_code}")

        code_for_output = generated_code # Default to generated code

        # SOP Step 4: Self-Critique (only if code generation was successful)
        if overall_status == TaskStatus.COMPLETED:
            critiqued_code, err_critique = await self._sop_self_critique(generated_code, requirements, context)
            if err_critique:
                final_output_parts.append(f"Self-Critique Error: {err_critique}")
                # Policy: use un-critiqued code or fail. Here, we use un-critiqued.
                logger.warn("Proceeding with un-critiqued code due to critique error.")
            else:
                if critiqued_code != generated_code:
                    final_output_parts.append(f"Self-Critiqued Code:\n{critiqued_code}")
                    logger.info("Code was refined during self-critique.")
                else:
                    final_output_parts.append("Self-Critique: No changes made to the code.")
                code_for_output = critiqued_code


        # SOP Step 5: Write Output Files (if indicated and previous steps didn't hard fail)
        if overall_status == TaskStatus.COMPLETED:
            err_write = await self._sop_write_output_files(code_for_output, original_task_description, context)
            if err_write:
                final_output_parts.append(f"File Writing Error: {err_write}")
                overall_status = TaskStatus.FAILED # If writing was requested and failed, the task fails.

        final_output_str = "\n---\n".join(final_output_parts)
        error_msg_for_result = None
        if overall_status == TaskStatus.FAILED:
            error_msg_for_result = "One or more SOP steps failed. See output for details."
            # Prepend a general error message if not already obvious from parts
            if not any("Error:" in part or "failed" in part.lower() for part in final_output_parts):
                 final_output_str = f"Task failed due to an unspecified error during SOP execution.\n---\n" + final_output_str

        logger.info(f"DeveloperAgent SOP for task {task_id_to_report} finished with status: {overall_status}")
        return TaskResult(
            task_id=task_id_to_report,
            status=overall_status,
            output=final_output_str,
            error_message=error_msg_for_result
        )

# Type hinting guards
if "AgentConfig" not in globals():
    class AgentConfig: agent_id: str; role_name: str; llm_config: Optional[Dict]
if "TaskContext" not in globals():
    class TaskContext: current_task: Any; project_context: Any
if "TaskStatus" not in globals():
    class TaskStatus: COMPLETED="COMPLETED"; FAILED="FAILED"
if "Task" not in globals():
    class Task: description: str; task_id: str
if "AbstractBaseAgent" not in globals():
    class AbstractBaseAgent: agent_config: AgentConfig; llm_aggregator: Any; tools_registry: Optional[ToolsRegistry]; def __init__(self,ac, llma, tr): pass; async def _use_llm(self, m) -> Any: pass; async def _use_tool(self, tn, ti) -> ToolOutput: pass # type: ignore
if "LLMAggregator" not in globals():
    class LLMAggregator: pass
if "ToolsRegistry" not in globals():
    class ToolsRegistry: pass
if "ChatMessage" not in globals():
    class ChatMessage: pass
if "ToolOutput" not in globals():
    class ToolOutput: error: Optional[str]; output: Any; status_code: int
